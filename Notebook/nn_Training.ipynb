{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
<<<<<<< Updated upstream
   "id": "d4d136df",
=======
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as ts\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
<<<<<<< Updated upstream
   "id": "5101b9cb",
=======
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")\n",
    "os.chdir(\"FinalDataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
<<<<<<< Updated upstream
   "id": "46ee700a",
=======
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"feature.csv\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 4,
   "id": "07d229bf",
=======
   "execution_count": 5,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>File</th>\n",
       "      <th>bodyLength</th>\n",
       "      <th>bscr</th>\n",
       "      <th>dse</th>\n",
       "      <th>dsr</th>\n",
       "      <th>entropy</th>\n",
       "      <th>hasHttp</th>\n",
       "      <th>hasHttps</th>\n",
       "      <th>has_ip</th>\n",
       "      <th>...</th>\n",
       "      <th>numParams</th>\n",
       "      <th>numTitles</th>\n",
       "      <th>num_%20</th>\n",
       "      <th>num_@</th>\n",
       "      <th>sbr</th>\n",
       "      <th>scriptLength</th>\n",
       "      <th>specialChars</th>\n",
       "      <th>sscr</th>\n",
       "      <th>urlIsLive</th>\n",
       "      <th>urlLength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>31</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.708307</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>64790</td>\n",
       "      <td>0.306050</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.576882</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.923800</td>\n",
       "      <td>59853</td>\n",
       "      <td>19829</td>\n",
       "      <td>3.018458</td>\n",
       "      <td>False</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>757</td>\n",
       "      <td>0.195509</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.205536</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>266310</td>\n",
       "      <td>0.230915</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.550931</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>648</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.312647</td>\n",
       "      <td>83261</td>\n",
       "      <td>61495</td>\n",
       "      <td>1.353947</td>\n",
       "      <td>False</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>40</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.689336</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          File  bodyLength      bscr  dse  dsr   entropy  \\\n",
       "0           0  spam_dataset          31  0.064516    0    0 -4.708307   \n",
       "1           1  spam_dataset       64790  0.306050    0    0 -4.576882   \n",
       "2           2  spam_dataset         757  0.195509    0    0 -4.205536   \n",
       "3           3  spam_dataset      266310  0.230915    0    0 -4.550931   \n",
       "4           4  spam_dataset          40  0.200000    0    0 -4.689336   \n",
       "\n",
       "   hasHttp  hasHttps  has_ip  ...  numParams  numTitles  num_%20  num_@  \\\n",
       "0     True     False       0  ...          0          0        0      0   \n",
       "1     True     False       0  ...          0         19        0      0   \n",
       "2     True     False       0  ...          0          1        0      0   \n",
       "3     True     False       0  ...          0        648        0      0   \n",
       "4     True     False       0  ...          2          1        0      0   \n",
       "\n",
       "        sbr  scriptLength  specialChars      sscr  urlIsLive  urlLength  \n",
       "0  0.000000             0             2  0.000000      False         81  \n",
       "1  0.923800         59853         19829  3.018458      False         58  \n",
       "2  0.000000             0           148  0.000000      False         46  \n",
       "3  0.312647         83261         61495  1.353947      False         52  \n",
       "4  0.000000             0             8  0.000000      False         83  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9a487fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Benign_list_big_final',\n",
       " 'Defacement',\n",
       " 'Malware_dataset',\n",
       " 'phishing_dataset',\n",
       " 'spam_dataset'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(data['File'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
<<<<<<< Updated upstream
   "id": "46dd0a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace(\"Benign_list_big_final\",\"Benign\",inplace=True)\n",
    "data.replace(\"Malware_dataset\",\"Malware\",inplace=True)\n",
    "data.replace(\"phishing_dataset\",\"Phishing\",inplace=True)\n",
    "data.replace(\"spam_dataset\",\"Spam\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d315269c",
=======
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns='Unnamed: 0',inplace=True)\n",
    "data.replace(True,1,inplace = True)\n",
    "data.replace(False,0,inplace = True)\n",
    "y = data[\"File\"]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 8,
   "id": "2131563d",
=======
   "execution_count": 7,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns = \"File\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 9,
   "id": "7a460215",
=======
   "execution_count": 8,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "Y = encoder.transform(y)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 10,
   "id": "c4274b9f",
=======
   "execution_count": 9,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X = scaler.fit_transform(data)\n",
    "X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 11,
   "id": "62d0cc35",
=======
   "execution_count": 10,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Masking, Embedding\n",
    "\n",
    "input_dim = len(data.columns)\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim = input_dim , activation = 'relu'))\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(5, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy' , optimizer = 'adam' , metrics = ['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 12,
   "id": "239859ba",
=======
   "execution_count": 11,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 13,
   "id": "9de7ea80",
=======
   "execution_count": 12,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28628 samples, validate on 12270 samples\n",
      "Epoch 1/50\n",
<<<<<<< Updated upstream
      "WARNING:tensorflow:AutoGraph could not transform <bound method Dense.call of <keras.layers.core.Dense object at 0x7fab4cdbd160>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmpm6feg0lt.py, line 48)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Dense.call of <keras.layers.core.Dense object at 0x7fab4cdbd160>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmpm6feg0lt.py, line 48)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "224/224 [==============================] - 13s 5ms/step - loss: 1.3799 - accuracy: 0.3827 - val_loss: 0.9924 - val_accuracy: 0.6090\n",
      "Epoch 2/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.9460 - accuracy: 0.6143 - val_loss: 0.8398 - val_accuracy: 0.6797\n",
      "Epoch 3/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.8313 - accuracy: 0.6743 - val_loss: 0.8221 - val_accuracy: 0.6825\n",
      "Epoch 4/50\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 0.7891 - accuracy: 0.6911 - val_loss: 0.7511 - val_accuracy: 0.6975\n",
      "Epoch 5/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.7282 - accuracy: 0.7165 - val_loss: 0.7157 - val_accuracy: 0.7127\n",
      "Epoch 6/50\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 0.7094 - accuracy: 0.7253 - val_loss: 0.6592 - val_accuracy: 0.7509\n",
      "Epoch 7/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.6636 - accuracy: 0.7423 - val_loss: 0.6616 - val_accuracy: 0.7267\n",
      "Epoch 8/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 0.7589 - val_loss: 0.6266 - val_accuracy: 0.7495\n",
      "Epoch 9/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.6237 - accuracy: 0.7618 - val_loss: 0.6238 - val_accuracy: 0.7548\n",
      "Epoch 10/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.6024 - accuracy: 0.7714 - val_loss: 0.5987 - val_accuracy: 0.7714\n",
      "Epoch 11/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.7753 - val_loss: 0.5851 - val_accuracy: 0.7671\n",
      "Epoch 12/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.5792 - accuracy: 0.7794 - val_loss: 0.5692 - val_accuracy: 0.7855\n",
      "Epoch 13/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.7837 - val_loss: 0.5551 - val_accuracy: 0.7848\n",
      "Epoch 14/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.7857 - val_loss: 0.5621 - val_accuracy: 0.7840\n",
      "Epoch 15/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7930 - val_loss: 0.5349 - val_accuracy: 0.7951\n",
      "Epoch 16/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.7966 - val_loss: 0.5397 - val_accuracy: 0.7929\n",
      "Epoch 17/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.7987 - val_loss: 0.5315 - val_accuracy: 0.7914\n",
      "Epoch 18/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.8026 - val_loss: 0.5257 - val_accuracy: 0.7977\n",
      "Epoch 19/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.8102 - val_loss: 0.5018 - val_accuracy: 0.8065\n",
      "Epoch 20/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.8069 - val_loss: 0.5214 - val_accuracy: 0.7982\n",
      "Epoch 21/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.8028 - val_loss: 0.5119 - val_accuracy: 0.8079\n",
      "Epoch 22/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.8086 - val_loss: 0.4943 - val_accuracy: 0.8139\n",
      "Epoch 23/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.8130 - val_loss: 0.5213 - val_accuracy: 0.7960\n",
      "Epoch 24/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.8140 - val_loss: 0.5161 - val_accuracy: 0.8007\n",
      "Epoch 25/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.8195 - val_loss: 0.4944 - val_accuracy: 0.8111\n",
      "Epoch 26/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.8185 - val_loss: 0.4948 - val_accuracy: 0.8131\n",
      "Epoch 27/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.8228 - val_loss: 0.4850 - val_accuracy: 0.8150\n",
      "Epoch 28/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.8190 - val_loss: 0.4818 - val_accuracy: 0.8148\n",
      "Epoch 29/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.8199 - val_loss: 0.4857 - val_accuracy: 0.8169\n",
      "Epoch 30/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.8233 - val_loss: 0.4949 - val_accuracy: 0.8150\n",
      "Epoch 31/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.8262 - val_loss: 0.4966 - val_accuracy: 0.8105\n",
      "Epoch 32/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.8239 - val_loss: 0.4901 - val_accuracy: 0.8156\n",
      "Epoch 33/50\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 0.4369 - accuracy: 0.8287 - val_loss: 0.5088 - val_accuracy: 0.8002\n",
      "Epoch 34/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.8251 - val_loss: 0.4882 - val_accuracy: 0.8196\n",
      "Epoch 35/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.8296 - val_loss: 0.4711 - val_accuracy: 0.8246\n",
      "Epoch 36/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.8268 - val_loss: 0.4632 - val_accuracy: 0.8258\n",
      "Epoch 37/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.8359 - val_loss: 0.4719 - val_accuracy: 0.8218\n",
      "Epoch 38/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.8321 - val_loss: 0.4631 - val_accuracy: 0.8287\n",
      "Epoch 39/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8377 - val_loss: 0.4496 - val_accuracy: 0.8311\n",
      "Epoch 40/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.8329 - val_loss: 0.4878 - val_accuracy: 0.8140\n",
      "Epoch 41/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.8375 - val_loss: 0.4643 - val_accuracy: 0.8306\n",
      "Epoch 42/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8421 - val_loss: 0.4558 - val_accuracy: 0.8311\n",
      "Epoch 43/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.8363 - val_loss: 0.4749 - val_accuracy: 0.8218\n",
      "Epoch 44/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4081 - accuracy: 0.8400 - val_loss: 0.4580 - val_accuracy: 0.8346\n",
      "Epoch 45/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.8395 - val_loss: 0.4693 - val_accuracy: 0.8267\n",
      "Epoch 46/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4050 - accuracy: 0.8429 - val_loss: 0.4571 - val_accuracy: 0.8308\n",
      "Epoch 47/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.3991 - accuracy: 0.8441 - val_loss: 0.4600 - val_accuracy: 0.8273\n",
      "Epoch 48/50\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 0.4104 - accuracy: 0.8406 - val_loss: 0.4599 - val_accuracy: 0.8315\n",
      "Epoch 49/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.3991 - accuracy: 0.8454 - val_loss: 0.4419 - val_accuracy: 0.8386\n",
      "Epoch 50/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.3898 - accuracy: 0.8465 - val_loss: 0.4399 - val_accuracy: 0.8380\n"
=======
      "28628/28628 [==============================] - 3s 90us/step - loss: 1.2346 - accuracy: 0.4709 - val_loss: 1.0316 - val_accuracy: 0.5826\n",
      "Epoch 2/50\n",
      "28628/28628 [==============================] - 1s 42us/step - loss: 0.9248 - accuracy: 0.6303 - val_loss: 0.8397 - val_accuracy: 0.6758\n",
      "Epoch 3/50\n",
      "28628/28628 [==============================] - 1s 40us/step - loss: 0.8110 - accuracy: 0.6809 - val_loss: 0.7710 - val_accuracy: 0.7051\n",
      "Epoch 4/50\n",
      "28628/28628 [==============================] - 1s 36us/step - loss: 0.7583 - accuracy: 0.7027 - val_loss: 0.7570 - val_accuracy: 0.7028\n",
      "Epoch 5/50\n",
      "28628/28628 [==============================] - 1s 39us/step - loss: 0.7242 - accuracy: 0.7175 - val_loss: 0.7033 - val_accuracy: 0.7297\n",
      "Epoch 6/50\n",
      "28628/28628 [==============================] - 1s 38us/step - loss: 0.6774 - accuracy: 0.7377 - val_loss: 0.6888 - val_accuracy: 0.7347\n",
      "Epoch 7/50\n",
      "28628/28628 [==============================] - 1s 50us/step - loss: 0.6629 - accuracy: 0.7437 - val_loss: 0.6914 - val_accuracy: 0.7308\n",
      "Epoch 8/50\n",
      "28628/28628 [==============================] - 1s 42us/step - loss: 0.6370 - accuracy: 0.7543 - val_loss: 0.6225 - val_accuracy: 0.7650\n",
      "Epoch 9/50\n",
      "28628/28628 [==============================] - 1s 46us/step - loss: 0.6169 - accuracy: 0.7633 - val_loss: 0.5881 - val_accuracy: 0.7754\n",
      "Epoch 10/50\n",
      "28628/28628 [==============================] - 1s 40us/step - loss: 0.5986 - accuracy: 0.7695 - val_loss: 0.6128 - val_accuracy: 0.7600\n",
      "Epoch 11/50\n",
      "28628/28628 [==============================] - 1s 38us/step - loss: 0.5875 - accuracy: 0.7742 - val_loss: 0.6271 - val_accuracy: 0.7549\n",
      "Epoch 12/50\n",
      "28628/28628 [==============================] - 1s 40us/step - loss: 0.5720 - accuracy: 0.7792 - val_loss: 0.5945 - val_accuracy: 0.7716\n",
      "Epoch 13/50\n",
      "28628/28628 [==============================] - 1s 38us/step - loss: 0.5599 - accuracy: 0.7864 - val_loss: 0.5508 - val_accuracy: 0.7932\n",
      "Epoch 14/50\n",
      "28628/28628 [==============================] - 1s 37us/step - loss: 0.5493 - accuracy: 0.7887 - val_loss: 0.5572 - val_accuracy: 0.7879\n",
      "Epoch 15/50\n",
      "28628/28628 [==============================] - 1s 37us/step - loss: 0.5429 - accuracy: 0.7904 - val_loss: 0.5757 - val_accuracy: 0.7706\n",
      "Epoch 16/50\n",
      "28628/28628 [==============================] - 1s 38us/step - loss: 0.5377 - accuracy: 0.7928 - val_loss: 0.5295 - val_accuracy: 0.7971\n",
      "Epoch 17/50\n",
      "28628/28628 [==============================] - 1s 38us/step - loss: 0.5305 - accuracy: 0.7977 - val_loss: 0.5489 - val_accuracy: 0.7905\n",
      "Epoch 18/50\n",
      "28628/28628 [==============================] - 1s 40us/step - loss: 0.5177 - accuracy: 0.8005 - val_loss: 0.5219 - val_accuracy: 0.7954\n",
      "Epoch 19/50\n",
      "28628/28628 [==============================] - 1s 33us/step - loss: 0.5131 - accuracy: 0.8028 - val_loss: 0.5185 - val_accuracy: 0.8011\n",
      "Epoch 20/50\n",
      "28628/28628 [==============================] - 1s 39us/step - loss: 0.5076 - accuracy: 0.8041 - val_loss: 0.5034 - val_accuracy: 0.8103\n",
      "Epoch 21/50\n",
      "28628/28628 [==============================] - 1s 39us/step - loss: 0.5023 - accuracy: 0.8055 - val_loss: 0.5324 - val_accuracy: 0.7907\n",
      "Epoch 22/50\n",
      "28628/28628 [==============================] - 1s 36us/step - loss: 0.4963 - accuracy: 0.8083 - val_loss: 0.5083 - val_accuracy: 0.8071\n",
      "Epoch 23/50\n",
      "28628/28628 [==============================] - 1s 41us/step - loss: 0.4978 - accuracy: 0.8079 - val_loss: 0.5036 - val_accuracy: 0.8093\n",
      "Epoch 24/50\n",
      "28628/28628 [==============================] - 1s 40us/step - loss: 0.4824 - accuracy: 0.8136 - val_loss: 0.5143 - val_accuracy: 0.8079\n",
      "Epoch 25/50\n",
      "28628/28628 [==============================] - 1s 38us/step - loss: 0.4859 - accuracy: 0.8126 - val_loss: 0.5044 - val_accuracy: 0.8101\n",
      "Epoch 26/50\n",
      "28628/28628 [==============================] - 1s 38us/step - loss: 0.4732 - accuracy: 0.8161 - val_loss: 0.5011 - val_accuracy: 0.8126\n",
      "Epoch 27/50\n",
      "28628/28628 [==============================] - 1s 37us/step - loss: 0.4761 - accuracy: 0.8137 - val_loss: 0.4922 - val_accuracy: 0.8106\n",
      "Epoch 28/50\n",
      "28628/28628 [==============================] - 1s 39us/step - loss: 0.4733 - accuracy: 0.8148 - val_loss: 0.4880 - val_accuracy: 0.8150\n",
      "Epoch 29/50\n",
      "28628/28628 [==============================] - 1s 38us/step - loss: 0.4712 - accuracy: 0.8170 - val_loss: 0.4891 - val_accuracy: 0.8192\n",
      "Epoch 30/50\n",
      "28628/28628 [==============================] - 1s 39us/step - loss: 0.4607 - accuracy: 0.8220 - val_loss: 0.4819 - val_accuracy: 0.8161\n",
      "Epoch 31/50\n",
      "28628/28628 [==============================] - 1s 37us/step - loss: 0.4624 - accuracy: 0.8208 - val_loss: 0.4898 - val_accuracy: 0.8152\n",
      "Epoch 32/50\n",
      "28628/28628 [==============================] - 1s 39us/step - loss: 0.4596 - accuracy: 0.8202 - val_loss: 0.5050 - val_accuracy: 0.8147\n",
      "Epoch 33/50\n",
      "28628/28628 [==============================] - 1s 33us/step - loss: 0.4569 - accuracy: 0.8228 - val_loss: 0.5023 - val_accuracy: 0.8129\n",
      "Epoch 34/50\n",
      "28628/28628 [==============================] - 1s 40us/step - loss: 0.4525 - accuracy: 0.8248 - val_loss: 0.5010 - val_accuracy: 0.8121\n",
      "Epoch 35/50\n",
      "28628/28628 [==============================] - 1s 41us/step - loss: 0.4524 - accuracy: 0.8221 - val_loss: 0.4847 - val_accuracy: 0.8154\n",
      "Epoch 36/50\n",
      "28628/28628 [==============================] - 1s 40us/step - loss: 0.4444 - accuracy: 0.8269 - val_loss: 0.4698 - val_accuracy: 0.8254\n",
      "Epoch 37/50\n",
      "28628/28628 [==============================] - 1s 44us/step - loss: 0.4435 - accuracy: 0.8282 - val_loss: 0.4645 - val_accuracy: 0.8244\n",
      "Epoch 38/50\n",
      "28628/28628 [==============================] - 1s 42us/step - loss: 0.4353 - accuracy: 0.8291 - val_loss: 0.4641 - val_accuracy: 0.8265\n",
      "Epoch 39/50\n",
      "28628/28628 [==============================] - 1s 37us/step - loss: 0.4334 - accuracy: 0.8324 - val_loss: 0.4766 - val_accuracy: 0.8232\n",
      "Epoch 40/50\n",
      "28628/28628 [==============================] - 1s 36us/step - loss: 0.4326 - accuracy: 0.8316 - val_loss: 0.4685 - val_accuracy: 0.8205\n",
      "Epoch 41/50\n",
      "28628/28628 [==============================] - 1s 41us/step - loss: 0.4291 - accuracy: 0.8318 - val_loss: 0.4659 - val_accuracy: 0.8187\n",
      "Epoch 42/50\n",
      "28628/28628 [==============================] - 1s 42us/step - loss: 0.4294 - accuracy: 0.8345 - val_loss: 0.4999 - val_accuracy: 0.8135\n",
      "Epoch 43/50\n",
      "28628/28628 [==============================] - 1s 38us/step - loss: 0.4272 - accuracy: 0.8335 - val_loss: 0.4639 - val_accuracy: 0.8276\n",
      "Epoch 44/50\n",
      "28628/28628 [==============================] - 1s 38us/step - loss: 0.4184 - accuracy: 0.8372 - val_loss: 0.4529 - val_accuracy: 0.8317\n",
      "Epoch 45/50\n",
      "28628/28628 [==============================] - 1s 40us/step - loss: 0.4263 - accuracy: 0.8347 - val_loss: 0.4400 - val_accuracy: 0.8355\n",
      "Epoch 46/50\n",
      "28628/28628 [==============================] - 1s 38us/step - loss: 0.4224 - accuracy: 0.8359 - val_loss: 0.4634 - val_accuracy: 0.8194\n",
      "Epoch 47/50\n",
      "28628/28628 [==============================] - 1s 37us/step - loss: 0.4173 - accuracy: 0.8387 - val_loss: 0.4585 - val_accuracy: 0.8301\n",
      "Epoch 48/50\n",
      "28628/28628 [==============================] - 1s 43us/step - loss: 0.4129 - accuracy: 0.8385 - val_loss: 0.4569 - val_accuracy: 0.8298\n",
      "Epoch 49/50\n",
      "28628/28628 [==============================] - 1s 38us/step - loss: 0.4125 - accuracy: 0.8386 - val_loss: 0.4589 - val_accuracy: 0.8316\n",
      "Epoch 50/50\n",
      "28628/28628 [==============================] - 1s 39us/step - loss: 0.4156 - accuracy: 0.8381 - val_loss: 0.4468 - val_accuracy: 0.8350\n"
>>>>>>> Stashed changes
     ]
    },
    {
     "data": {
      "text/plain": [
<<<<<<< Updated upstream
       "<keras.callbacks.History at 0x7fab2f32c940>"
      ]
     },
     "execution_count": 13,
=======
       "<keras.callbacks.callbacks.History at 0x20e1b1b2648>"
      ]
     },
     "execution_count": 12,
>>>>>>> Stashed changes
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,np_utils.to_categorical(y_train),epochs = 50,validation_split=0.3, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 14,
   "id": "89d36302",
=======
   "execution_count": 13,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 15,
   "id": "1df141b4",
=======
   "execution_count": 14,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 16,
   "id": "fdd42b76",
=======
   "execution_count": 15,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "0.8454485439741803\n"
=======
      "0.8432480011736229\n"
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(accuracy_score(y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 17,
   "id": "f49f6a57",
=======
   "execution_count": 16,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
<<<<<<< Updated upstream
      "      Benign       0.93      0.95      0.94      2735\n",
      "  Defacement       0.74      0.79      0.77      2499\n",
      "     Malware       0.81      0.91      0.86      2834\n",
      "    Phishing       0.82      0.72      0.77      2477\n",
      "        Spam       0.92      0.84      0.88      3088\n",
      "\n",
      "    accuracy                           0.85     13633\n",
      "   macro avg       0.84      0.84      0.84     13633\n",
      "weighted avg       0.85      0.85      0.85     13633\n",
=======
      "      Benign       0.96      0.92      0.94      2735\n",
      "  Defacement       0.84      0.68      0.75      2499\n",
      "     Malware       0.83      0.89      0.86      2834\n",
      "    Phishing       0.74      0.79      0.76      2477\n",
      "        Spam       0.85      0.91      0.88      3088\n",
      "\n",
      "    accuracy                           0.84     13633\n",
      "   macro avg       0.84      0.84      0.84     13633\n",
      "weighted avg       0.85      0.84      0.84     13633\n",
>>>>>>> Stashed changes
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Benign','Defacement','Malware','Phishing','Spam']\n",
    "print(classification_report(y_test, predicted, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 18,
   "id": "2d921cc0",
=======
   "execution_count": 17,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")\n",
    "os.chdir(\"models\")\n",
    "model.save(\"Model_v2.h5\")\n",
    "np.save('lblenc_v1.npy', encoder.classes_)\n",
    "scalerfile = 'scaler_v1.sav'\n",
    "pickle.dump(scaler, open(scalerfile, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model\n",
    "converter = ts.lite.TFLiteConverter.from_saved_model(\"Model_v1\") # path to the SavedModel directory\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200968"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_model_file = pathlib.Path('tflite_model.tflite')\n",
    "tflite_model_file.write_bytes(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the model\n",
    "converter = ts.lite.TFLiteConverter.from_saved_model(\"Model_v1\")\n",
    "converter.optimizations = [ts.lite.Optimize.DEFAULT]\n",
    "tflite_quant_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55912"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_model_file = pathlib.Path('tflite_quant_model.tflite')\n",
    "tflite_model_file.write_bytes(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faea9809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as ts\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a152931",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")\n",
    "os.chdir(\"FinalDataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74681b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a91dd5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"feature.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8544a3d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>File</th>\n",
       "      <th>bodyLength</th>\n",
       "      <th>bscr</th>\n",
       "      <th>dse</th>\n",
       "      <th>dsr</th>\n",
       "      <th>entropy</th>\n",
       "      <th>hasHttp</th>\n",
       "      <th>hasHttps</th>\n",
       "      <th>has_ip</th>\n",
       "      <th>...</th>\n",
       "      <th>numParams</th>\n",
       "      <th>numTitles</th>\n",
       "      <th>num_%20</th>\n",
       "      <th>num_@</th>\n",
       "      <th>sbr</th>\n",
       "      <th>scriptLength</th>\n",
       "      <th>specialChars</th>\n",
       "      <th>sscr</th>\n",
       "      <th>urlIsLive</th>\n",
       "      <th>urlLength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>31</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.708307</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>64790</td>\n",
       "      <td>0.306050</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.576882</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.923800</td>\n",
       "      <td>59853</td>\n",
       "      <td>19829</td>\n",
       "      <td>3.018458</td>\n",
       "      <td>False</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>757</td>\n",
       "      <td>0.195509</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.205536</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>266310</td>\n",
       "      <td>0.230915</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.550931</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>648</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.312647</td>\n",
       "      <td>83261</td>\n",
       "      <td>61495</td>\n",
       "      <td>1.353947</td>\n",
       "      <td>False</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>spam_dataset</td>\n",
       "      <td>40</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.689336</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          File  bodyLength      bscr  dse  dsr   entropy  \\\n",
       "0           0  spam_dataset          31  0.064516    0    0 -4.708307   \n",
       "1           1  spam_dataset       64790  0.306050    0    0 -4.576882   \n",
       "2           2  spam_dataset         757  0.195509    0    0 -4.205536   \n",
       "3           3  spam_dataset      266310  0.230915    0    0 -4.550931   \n",
       "4           4  spam_dataset          40  0.200000    0    0 -4.689336   \n",
       "\n",
       "   hasHttp  hasHttps  has_ip  ...  numParams  numTitles  num_%20  num_@  \\\n",
       "0     True     False       0  ...          0          0        0      0   \n",
       "1     True     False       0  ...          0         19        0      0   \n",
       "2     True     False       0  ...          0          1        0      0   \n",
       "3     True     False       0  ...          0        648        0      0   \n",
       "4     True     False       0  ...          2          1        0      0   \n",
       "\n",
       "        sbr  scriptLength  specialChars      sscr  urlIsLive  urlLength  \n",
       "0  0.000000             0             2  0.000000      False         81  \n",
       "1  0.923800         59853         19829  3.018458      False         58  \n",
       "2  0.000000             0           148  0.000000      False         46  \n",
       "3  0.312647         83261         61495  1.353947      False         52  \n",
       "4  0.000000             0             8  0.000000      False         83  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "957b08c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns='Unnamed: 0',inplace=True)\n",
    "data.replace(True,1,inplace = True)\n",
    "data.replace(False,0,inplace = True)\n",
    "y = data[\"File\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2604184",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns = \"File\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f9586ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "Y = encoder.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "947f69a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X = scaler.fit_transform(data)\n",
    "X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9047a458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Masking, Embedding\n",
    "\n",
    "input_dim = len(data.columns)\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim = input_dim , activation = 'relu'))\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(5, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy' , optimizer = 'adam' , metrics = ['accuracy',f1_m,precision_m, recall_m] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "576984fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd45b7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Dense.call of <keras.layers.core.Dense object at 0x7fa0c6c091c0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmp1cw_fots.py, line 48)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Dense.call of <keras.layers.core.Dense object at 0x7fa0c6c091c0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmp1cw_fots.py, line 48)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "224/224 [==============================] - 12s 4ms/step - loss: 1.4192 - accuracy: 0.3614 - f1_m: 0.1632 - precision_m: 0.5647 - recall_m: 0.0977 - val_loss: 1.1478 - val_accuracy: 0.5310 - val_f1_m: 0.4330 - val_precision_m: 0.7517 - val_recall_m: 0.3049\n",
      "Epoch 2/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 1.0882 - accuracy: 0.5574 - f1_m: 0.4769 - precision_m: 0.7710 - recall_m: 0.3484 - val_loss: 0.9469 - val_accuracy: 0.6041 - val_f1_m: 0.6030 - val_precision_m: 0.7763 - val_recall_m: 0.4936\n",
      "Epoch 3/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.9285 - accuracy: 0.6340 - f1_m: 0.6153 - precision_m: 0.8100 - recall_m: 0.4973 - val_loss: 0.8328 - val_accuracy: 0.6795 - val_f1_m: 0.6584 - val_precision_m: 0.8112 - val_recall_m: 0.5548\n",
      "Epoch 4/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.8224 - accuracy: 0.6798 - f1_m: 0.6574 - precision_m: 0.8191 - recall_m: 0.5501 - val_loss: 0.7743 - val_accuracy: 0.6980 - val_f1_m: 0.6898 - val_precision_m: 0.8088 - val_recall_m: 0.6021\n",
      "Epoch 5/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.7606 - accuracy: 0.7034 - f1_m: 0.6810 - precision_m: 0.8221 - recall_m: 0.5822 - val_loss: 0.7813 - val_accuracy: 0.6913 - val_f1_m: 0.6662 - val_precision_m: 0.8005 - val_recall_m: 0.5711\n",
      "Epoch 6/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.7047 - accuracy: 0.7246 - f1_m: 0.7065 - precision_m: 0.8313 - recall_m: 0.6155 - val_loss: 0.6737 - val_accuracy: 0.7343 - val_f1_m: 0.7145 - val_precision_m: 0.8431 - val_recall_m: 0.6206\n",
      "Epoch 7/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.6789 - accuracy: 0.7283 - f1_m: 0.7145 - precision_m: 0.8325 - recall_m: 0.6271 - val_loss: 0.6641 - val_accuracy: 0.7402 - val_f1_m: 0.7212 - val_precision_m: 0.8422 - val_recall_m: 0.6315\n",
      "Epoch 8/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.6455 - accuracy: 0.7487 - f1_m: 0.7342 - precision_m: 0.8390 - recall_m: 0.6534 - val_loss: 0.6421 - val_accuracy: 0.7457 - val_f1_m: 0.7494 - val_precision_m: 0.8205 - val_recall_m: 0.6901\n",
      "Epoch 9/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.6235 - accuracy: 0.7595 - f1_m: 0.7509 - precision_m: 0.8452 - recall_m: 0.6762 - val_loss: 0.6045 - val_accuracy: 0.7625 - val_f1_m: 0.7540 - val_precision_m: 0.8524 - val_recall_m: 0.6765\n",
      "Epoch 10/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.6077 - accuracy: 0.7647 - f1_m: 0.7560 - precision_m: 0.8426 - recall_m: 0.6863 - val_loss: 0.6621 - val_accuracy: 0.7297 - val_f1_m: 0.7326 - val_precision_m: 0.8102 - val_recall_m: 0.6691\n",
      "Epoch 11/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.5867 - accuracy: 0.7732 - f1_m: 0.7614 - precision_m: 0.8445 - recall_m: 0.6940 - val_loss: 0.5894 - val_accuracy: 0.7579 - val_f1_m: 0.7615 - val_precision_m: 0.8582 - val_recall_m: 0.6849\n",
      "Epoch 12/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.5754 - accuracy: 0.7764 - f1_m: 0.7688 - precision_m: 0.8489 - recall_m: 0.7032 - val_loss: 0.5787 - val_accuracy: 0.7790 - val_f1_m: 0.7672 - val_precision_m: 0.8526 - val_recall_m: 0.6979\n",
      "Epoch 13/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.7792 - f1_m: 0.7735 - precision_m: 0.8477 - recall_m: 0.7120 - val_loss: 0.5737 - val_accuracy: 0.7822 - val_f1_m: 0.7741 - val_precision_m: 0.8568 - val_recall_m: 0.7064\n",
      "Epoch 14/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7829 - f1_m: 0.7789 - precision_m: 0.8500 - recall_m: 0.7193 - val_loss: 0.5533 - val_accuracy: 0.7852 - val_f1_m: 0.7817 - val_precision_m: 0.8495 - val_recall_m: 0.7243\n",
      "Epoch 15/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.5585 - accuracy: 0.7856 - f1_m: 0.7812 - precision_m: 0.8528 - recall_m: 0.7215 - val_loss: 0.5703 - val_accuracy: 0.7811 - val_f1_m: 0.7713 - val_precision_m: 0.8474 - val_recall_m: 0.7082\n",
      "Epoch 16/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.7913 - f1_m: 0.7842 - precision_m: 0.8548 - recall_m: 0.7251 - val_loss: 0.5558 - val_accuracy: 0.7876 - val_f1_m: 0.7846 - val_precision_m: 0.8531 - val_recall_m: 0.7268\n",
      "Epoch 17/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7894 - f1_m: 0.7865 - precision_m: 0.8549 - recall_m: 0.7287 - val_loss: 0.5292 - val_accuracy: 0.7982 - val_f1_m: 0.7937 - val_precision_m: 0.8617 - val_recall_m: 0.7360\n",
      "Epoch 18/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7974 - f1_m: 0.7943 - precision_m: 0.8604 - recall_m: 0.7383 - val_loss: 0.5171 - val_accuracy: 0.8013 - val_f1_m: 0.7954 - val_precision_m: 0.8660 - val_recall_m: 0.7359\n",
      "Epoch 19/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.7962 - f1_m: 0.7927 - precision_m: 0.8580 - recall_m: 0.7371 - val_loss: 0.5400 - val_accuracy: 0.7936 - val_f1_m: 0.7945 - val_precision_m: 0.8463 - val_recall_m: 0.7491\n",
      "Epoch 20/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7989 - f1_m: 0.7970 - precision_m: 0.8590 - recall_m: 0.7439 - val_loss: 0.5206 - val_accuracy: 0.7993 - val_f1_m: 0.7911 - val_precision_m: 0.8646 - val_recall_m: 0.7296\n",
      "Epoch 21/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.8080 - f1_m: 0.8038 - precision_m: 0.8676 - recall_m: 0.7493 - val_loss: 0.5273 - val_accuracy: 0.8027 - val_f1_m: 0.7897 - val_precision_m: 0.8509 - val_recall_m: 0.7372\n",
      "Epoch 22/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.8063 - f1_m: 0.8048 - precision_m: 0.8661 - recall_m: 0.7521 - val_loss: 0.5189 - val_accuracy: 0.8030 - val_f1_m: 0.7973 - val_precision_m: 0.8687 - val_recall_m: 0.7371\n",
      "Epoch 23/50\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 0.4953 - accuracy: 0.8069 - f1_m: 0.8049 - precision_m: 0.8672 - recall_m: 0.7513 - val_loss: 0.5155 - val_accuracy: 0.7998 - val_f1_m: 0.8009 - val_precision_m: 0.8557 - val_recall_m: 0.7531\n",
      "Epoch 24/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.8118 - f1_m: 0.8085 - precision_m: 0.8673 - recall_m: 0.7575 - val_loss: 0.5024 - val_accuracy: 0.8147 - val_f1_m: 0.8076 - val_precision_m: 0.8675 - val_recall_m: 0.7558\n",
      "Epoch 25/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4962 - accuracy: 0.8111 - f1_m: 0.8056 - precision_m: 0.8665 - recall_m: 0.7532 - val_loss: 0.4967 - val_accuracy: 0.8112 - val_f1_m: 0.8002 - val_precision_m: 0.8672 - val_recall_m: 0.7432\n",
      "Epoch 26/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.8172 - f1_m: 0.8129 - precision_m: 0.8726 - recall_m: 0.7614 - val_loss: 0.4966 - val_accuracy: 0.8076 - val_f1_m: 0.8030 - val_precision_m: 0.8566 - val_recall_m: 0.7559\n",
      "Epoch 27/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.8155 - f1_m: 0.8137 - precision_m: 0.8685 - recall_m: 0.7659 - val_loss: 0.4896 - val_accuracy: 0.8190 - val_f1_m: 0.8177 - val_precision_m: 0.8674 - val_recall_m: 0.7738\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.8154 - f1_m: 0.8144 - precision_m: 0.8709 - recall_m: 0.7653 - val_loss: 0.4968 - val_accuracy: 0.8150 - val_f1_m: 0.8085 - val_precision_m: 0.8653 - val_recall_m: 0.7590\n",
      "Epoch 29/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.8163 - f1_m: 0.8137 - precision_m: 0.8714 - recall_m: 0.7636 - val_loss: 0.4950 - val_accuracy: 0.8118 - val_f1_m: 0.8057 - val_precision_m: 0.8630 - val_recall_m: 0.7559\n",
      "Epoch 30/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.8240 - f1_m: 0.8177 - precision_m: 0.8741 - recall_m: 0.7686 - val_loss: 0.4969 - val_accuracy: 0.8114 - val_f1_m: 0.8116 - val_precision_m: 0.8619 - val_recall_m: 0.7670\n",
      "Epoch 31/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.8226 - f1_m: 0.8210 - precision_m: 0.8728 - recall_m: 0.7755 - val_loss: 0.4786 - val_accuracy: 0.8135 - val_f1_m: 0.8089 - val_precision_m: 0.8790 - val_recall_m: 0.7497\n",
      "Epoch 32/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.8218 - f1_m: 0.8234 - precision_m: 0.8757 - recall_m: 0.7775 - val_loss: 0.4861 - val_accuracy: 0.8167 - val_f1_m: 0.8152 - val_precision_m: 0.8633 - val_recall_m: 0.7725\n",
      "Epoch 33/50\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 0.4536 - accuracy: 0.8262 - f1_m: 0.8225 - precision_m: 0.8753 - recall_m: 0.7761 - val_loss: 0.4734 - val_accuracy: 0.8204 - val_f1_m: 0.8228 - val_precision_m: 0.8710 - val_recall_m: 0.7800\n",
      "Epoch 34/50\n",
      "224/224 [==============================] - 1s 2ms/step - loss: 0.4554 - accuracy: 0.8252 - f1_m: 0.8242 - precision_m: 0.8768 - recall_m: 0.7780 - val_loss: 0.4827 - val_accuracy: 0.8205 - val_f1_m: 0.8207 - val_precision_m: 0.8774 - val_recall_m: 0.7713\n",
      "Epoch 35/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.8260 - f1_m: 0.8228 - precision_m: 0.8749 - recall_m: 0.7770 - val_loss: 0.5481 - val_accuracy: 0.7944 - val_f1_m: 0.8007 - val_precision_m: 0.8394 - val_recall_m: 0.7656\n",
      "Epoch 36/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.8247 - f1_m: 0.8245 - precision_m: 0.8751 - recall_m: 0.7797 - val_loss: 0.4724 - val_accuracy: 0.8222 - val_f1_m: 0.8150 - val_precision_m: 0.8783 - val_recall_m: 0.7604\n",
      "Epoch 37/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.8252 - f1_m: 0.8236 - precision_m: 0.8756 - recall_m: 0.7780 - val_loss: 0.4732 - val_accuracy: 0.8216 - val_f1_m: 0.8211 - val_precision_m: 0.8678 - val_recall_m: 0.7794\n",
      "Epoch 38/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.8279 - f1_m: 0.8254 - precision_m: 0.8765 - recall_m: 0.7803 - val_loss: 0.4562 - val_accuracy: 0.8324 - val_f1_m: 0.8296 - val_precision_m: 0.8862 - val_recall_m: 0.7802\n",
      "Epoch 39/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.8324 - f1_m: 0.8299 - precision_m: 0.8823 - recall_m: 0.7837 - val_loss: 0.4643 - val_accuracy: 0.8268 - val_f1_m: 0.8260 - val_precision_m: 0.8688 - val_recall_m: 0.7875\n",
      "Epoch 40/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.8347 - f1_m: 0.8353 - precision_m: 0.8817 - recall_m: 0.7938 - val_loss: 0.4697 - val_accuracy: 0.8249 - val_f1_m: 0.8250 - val_precision_m: 0.8713 - val_recall_m: 0.7837\n",
      "Epoch 41/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.8337 - f1_m: 0.8330 - precision_m: 0.8812 - recall_m: 0.7901 - val_loss: 0.4649 - val_accuracy: 0.8276 - val_f1_m: 0.8259 - val_precision_m: 0.8808 - val_recall_m: 0.7777\n",
      "Epoch 42/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.8294 - f1_m: 0.8303 - precision_m: 0.8827 - recall_m: 0.7842 - val_loss: 0.4471 - val_accuracy: 0.8301 - val_f1_m: 0.8299 - val_precision_m: 0.8837 - val_recall_m: 0.7826\n",
      "Epoch 43/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.8397 - f1_m: 0.8394 - precision_m: 0.8868 - recall_m: 0.7972 - val_loss: 0.4944 - val_accuracy: 0.8173 - val_f1_m: 0.8165 - val_precision_m: 0.8619 - val_recall_m: 0.7760\n",
      "Epoch 44/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8330 - f1_m: 0.8317 - precision_m: 0.8786 - recall_m: 0.7898 - val_loss: 0.4565 - val_accuracy: 0.8344 - val_f1_m: 0.8298 - val_precision_m: 0.8842 - val_recall_m: 0.7820\n",
      "Epoch 45/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.8391 - f1_m: 0.8394 - precision_m: 0.8861 - recall_m: 0.7977 - val_loss: 0.4682 - val_accuracy: 0.8262 - val_f1_m: 0.8267 - val_precision_m: 0.8724 - val_recall_m: 0.7858\n",
      "Epoch 46/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.8396 - f1_m: 0.8381 - precision_m: 0.8872 - recall_m: 0.7945 - val_loss: 0.4494 - val_accuracy: 0.8355 - val_f1_m: 0.8325 - val_precision_m: 0.8773 - val_recall_m: 0.7924\n",
      "Epoch 47/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.8371 - f1_m: 0.8354 - precision_m: 0.8843 - recall_m: 0.7920 - val_loss: 0.4445 - val_accuracy: 0.8376 - val_f1_m: 0.8369 - val_precision_m: 0.8774 - val_recall_m: 0.8003\n",
      "Epoch 48/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4040 - accuracy: 0.8432 - f1_m: 0.8431 - precision_m: 0.8917 - recall_m: 0.7999 - val_loss: 0.4496 - val_accuracy: 0.8332 - val_f1_m: 0.8347 - val_precision_m: 0.8725 - val_recall_m: 0.8002\n",
      "Epoch 49/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.8405 - f1_m: 0.8411 - precision_m: 0.8882 - recall_m: 0.7991 - val_loss: 0.4569 - val_accuracy: 0.8360 - val_f1_m: 0.8315 - val_precision_m: 0.8808 - val_recall_m: 0.7878\n",
      "Epoch 50/50\n",
      "224/224 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.8444 - f1_m: 0.8416 - precision_m: 0.8891 - recall_m: 0.7993 - val_loss: 0.4697 - val_accuracy: 0.8229 - val_f1_m: 0.8276 - val_precision_m: 0.8709 - val_recall_m: 0.7886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa0c748d8b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,np_utils.to_categorical(y_train),epochs = 50,validation_split=0.3, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86031098",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7abb711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05a66c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8322452871708355\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(accuracy_score(y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c22be8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.88      0.97      0.92      2735\n",
      "  Defacement       0.84      0.67      0.75      2499\n",
      "     Malware       0.82      0.87      0.84      2834\n",
      "    Phishing       0.73      0.78      0.75      2477\n",
      "        Spam       0.89      0.85      0.87      3088\n",
      "\n",
      "    accuracy                           0.83     13633\n",
      "   macro avg       0.83      0.83      0.83     13633\n",
      "weighted avg       0.83      0.83      0.83     13633\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Benign','Defacement','Malware','Phishing','Spam']\n",
    "print(classification_report(y_test, predicted, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67890176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir(\"../\")\n",
    "#os.chdir(\"models\")\n",
    "model.save(\"Model_v1.h5\")\n",
    "np.save('lblenc.npy', encoder.classes_)\n",
    "scalerfile = 'scaler.sav'\n",
    "pickle.dump(scaler, open(scalerfile, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb54d210",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerfile = 'scaler.sav'\n",
    "scaler1 = pickle.load(open(scalerfile, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa2b1086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement sklearn==0.24.2 (from versions: 0.0)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for sklearn==0.24.2\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn==0.24.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55836393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (20.3.3)\n",
      "Collecting pip\n",
      "  Downloading pip-21.1.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.5 MB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 20.3.3\n",
      "    Uninstalling pip-20.3.3:\n",
      "      Successfully uninstalled pip-20.3.3\n",
      "Successfully installed pip-21.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a315c8f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python38064bit1060d4750c904259afeb7847dfa8ded2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
